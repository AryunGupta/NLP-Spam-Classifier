{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP Spam Predictor.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOmRU5oNXcbuvpc9MGdMcwM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AryunGupta/NLP-Spam-Classifier/blob/main/NLP_Spam_Predictor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-Cx128IqeaX",
        "outputId": "45e05323-a360-4dc2-be92-1aab86dceeb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk # natural language toolkit for NLP\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"Spam Email raw text for NLP.csv\") # takes long to load be patient\n",
        "\n",
        "df.head()\n",
        "# df[\"CATEGORY\"].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "ms9ZP1c8rc7W",
        "outputId": "cba6ba4b-211d-43c1-fab0-6dad3c9d30fc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   CATEGORY                                            MESSAGE  \\\n",
              "0         1  Dear Homeowner,\\n\\n \\n\\nInterest Rates are at ...   \n",
              "1         1  ATTENTION: This is a MUST for ALL Computer Use...   \n",
              "2         1  This is a multi-part message in MIME format.\\n...   \n",
              "3         1  IMPORTANT INFORMATION:\\n\\n\\n\\nThe new domain n...   \n",
              "4         1  This is the bottom line.  If you can GIVE AWAY...   \n",
              "\n",
              "                                FILE_NAME  \n",
              "0  00249.5f45607c1bffe89f60ba1ec9f878039a  \n",
              "1  00373.ebe8670ac56b04125c25100a36ab0510  \n",
              "2  00214.1367039e50dc6b7adb0f2aa8aba83216  \n",
              "3  00210.050ffd105bd4e006771ee63cabc59978  \n",
              "4  00033.9babb58d9298daa2963d4f514193d7d6  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7c5417de-4471-4700-86f5-9483c716a56d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CATEGORY</th>\n",
              "      <th>MESSAGE</th>\n",
              "      <th>FILE_NAME</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Dear Homeowner,\\n\\n \\n\\nInterest Rates are at ...</td>\n",
              "      <td>00249.5f45607c1bffe89f60ba1ec9f878039a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>ATTENTION: This is a MUST for ALL Computer Use...</td>\n",
              "      <td>00373.ebe8670ac56b04125c25100a36ab0510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>This is a multi-part message in MIME format.\\n...</td>\n",
              "      <td>00214.1367039e50dc6b7adb0f2aa8aba83216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>IMPORTANT INFORMATION:\\n\\n\\n\\nThe new domain n...</td>\n",
              "      <td>00210.050ffd105bd4e006771ee63cabc59978</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>This is the bottom line.  If you can GIVE AWAY...</td>\n",
              "      <td>00033.9babb58d9298daa2963d4f514193d7d6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7c5417de-4471-4700-86f5-9483c716a56d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7c5417de-4471-4700-86f5-9483c716a56d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7c5417de-4471-4700-86f5-9483c716a56d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "0- not spam, 1-spam\n",
        "\n",
        "So, there are 3900 not spam and 1896 spam emails in this dataset.\n",
        "\n",
        "I applied some information retrieval concepts to make each email more concise, thus helping in classifying as spam/not spam.\n",
        "\n",
        "I used lemmatization instead of stemming as lemmatization considers context. This way it will be more useful in the machine learning part of this project."
      ],
      "metadata": {
        "id": "IvNI5QN8srGp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords = stopwords.words('english')\n",
        "def tokenizer(s):\n",
        "  # to tokenize- remove unnecessary stuff like brackets, commas, etc\n",
        "  sentence_tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
        "  # lemmatizing instead of stemming\n",
        "  lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "  # tokenize\n",
        "  tokens = sentence_tokenizer.tokenize(s)\n",
        "  # turn each token lowercase\n",
        "  lowercased_tokens = [token.lower() for token in tokens]\n",
        "  # lemmatize each lowercase token\n",
        "  lemmatized_tokens = [lemmatizer.lemmatize(token) for token in lowercased_tokens]\n",
        "  # add the word tokens to a list if it is not a stop word\n",
        "  tokens = [token for token in lemmatized_tokens if token not in stopwords]\n",
        "\n",
        "  return tokens\n",
        "\n",
        "# testing out the above function with a random string\n",
        "test_message = \"HeY,, lMnOPq feet it going? <HTML>!bad? bads 'randoms' badly\"\n",
        "tokenizer(test_message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMv3ysBds2aV",
        "outputId": "5c004842-2171-417c-9df7-075631ee6b09"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hey', 'lmnopq', 'foot', 'going', 'html', 'bad', 'bad', 'randoms', 'badly']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I partitoned the dataframe into train and test data. 80% of the data can be used for training and the rest for testing. To do so, I shuffled the dataset first."
      ],
      "metadata": {
        "id": "UA6pUQ-bATnn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# shuffling the dataframe\n",
        "df = df.sample(frac=1, random_state=1)\n",
        "df.reset_index(drop=\"True\") # in case the indexes got shuffled too\n",
        "\n",
        "# getting the 80%th point in our dataframe where we will split for train/test\n",
        "split_index = int(len(df) * 0.8)\n",
        "\n",
        "train_df = df[:split_index]\n",
        "test_df = df[split_index:]\n",
        "\n",
        "# indexes may get messed up so we need to fix that\n",
        "train_df = train_df.reset_index(drop=True)\n",
        "test_df = test_df.reset_index(drop=True)\n",
        "\n",
        "# train_df, test_df"
      ],
      "metadata": {
        "id": "3-3rx-O1ARW1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A good to predict whether an email is spam is by checking which words occur frequently in spam emails. So, I made dictionary where the key represents the tokenized word and value is the number of times it occurs in our dataframe."
      ],
      "metadata": {
        "id": "1CnvkbjkDg3w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "token_counter = {} # a dictionary that keeps tokens and the number of times they appear\n",
        "\n",
        "for message in train_df[\"MESSAGE\"]:\n",
        "  # each message in our dataframe gets tokenized\n",
        "  tokenized_message = tokenizer(message)\n",
        "\n",
        "  for token in tokenized_message:\n",
        "    # if the token in the tokenized message is not in the dictionary, we add it to it\n",
        "    if token not in token_counter:\n",
        "      token_counter[token] = 1\n",
        "    # if it is in the dictionary, we increment its frequency by 1\n",
        "    else:\n",
        "      token_counter[token] += 1\n",
        "\n",
        "\n",
        "len(token_counter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05nHfM7_JHXa",
        "outputId": "ad7bb683-5c59-4cc4-fc1b-dbeadce4364d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "86415"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "These are too many tokens. Only a handful of these will actually be useful (the ones that appear most frequently). To do so, I set an arbitrary threshold value. If a token appears more than the threshold number of times, it is kept as it may be an indicator for spam."
      ],
      "metadata": {
        "id": "9vZFrjTrKMjt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pass_threshold(token, threshold):\n",
        "\n",
        "  # if a token is not even in the dictionary, we don't need it\n",
        "  if token not in token_counter:\n",
        "    return False\n",
        "  else:\n",
        "    return (token_counter[token] > threshold)\n",
        "\n",
        "spam_detectors = set()\n",
        "\n",
        "'''\n",
        "now we pass each token in the dictionary into the above function to get only the tokens that pass the threshold\n",
        "we can toy around with the threshold to see which gives good outputs\n",
        "the model accuracy in the end works better with 8000 than with some other thresholds\n",
        "'''\n",
        "for token in token_counter:\n",
        "  if pass_threshold(token, 8000):\n",
        "    spam_detectors.add(token)\n",
        "\n",
        "spam_detectors = list(spam_detectors) # this will order the elements and make it easier to use\n",
        "spam_detectors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzBjijdiKi-z",
        "outputId": "70a9e5c3-d1d4-4455-d1fa-775da7dc802f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['br',\n",
              " 'font',\n",
              " 'p',\n",
              " 'size',\n",
              " 'com',\n",
              " 'face',\n",
              " 'td',\n",
              " 'http',\n",
              " 'b',\n",
              " 'tr',\n",
              " 'width',\n",
              " '0',\n",
              " 'color',\n",
              " '1',\n",
              " '3d',\n",
              " 'nbsp']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The machine learning model can be based on the number of times each element in spam_detectors appears."
      ],
      "metadata": {
        "id": "BBIxbICHMwR4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index_detector = {t:i for t, i in zip(spam_detectors, range(len(spam_detectors)))}\n",
        "\n",
        "index_detector"
      ],
      "metadata": {
        "id": "qxf-Hjc3M24V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b195af26-f317-46f6-c961-0c31326376f9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'br': 0,\n",
              " 'font': 1,\n",
              " 'p': 2,\n",
              " 'size': 3,\n",
              " 'com': 4,\n",
              " 'face': 5,\n",
              " 'td': 6,\n",
              " 'http': 7,\n",
              " 'b': 8,\n",
              " 'tr': 9,\n",
              " 'width': 10,\n",
              " '0': 11,\n",
              " 'color': 12,\n",
              " '1': 13,\n",
              " '3d': 14,\n",
              " 'nbsp': 15}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The idea is that for each tokenized message in our dataframe, we check how many times the above words appear. If they appear too many times, the message is likely to be spam.\n",
        "\n",
        "I implemented this using a vector."
      ],
      "metadata": {
        "id": "jkBVo6zu8pgm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The intuition can be seen as follows:\n",
        "# tokenizer(\"3d b <br> .com bad font font com randoms\")\n",
        "\n",
        "# The output for it will be:\n",
        "# ['3d', 'b', 'br', 'com', 'bad', 'font', 'font', 'com', 'randoms']\n",
        "\n",
        "# ->  br  b  size  3d  com  font  p  http   td   tr      -> spam detector words\n",
        "# ->  0    1    2    3   4    5    6    7   8   9        -> index of the spam detector words\n",
        "# -> [1,   1,   0,   1,  2,   2,   0,   0,  0,  0]       -> number of times those words appeared in the text\n"
      ],
      "metadata": {
        "id": "VXdioKT04-Jw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We want to get the above kind of vector for a message"
      ],
      "metadata": {
        "id": "2f2nWA_x594A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_vector(message):\n",
        "\n",
        "  # initializing a numpy vector of 0s as at the beginning we haven't seen any words\n",
        "  vector = np.zeros(len(spam_detectors))\n",
        "\n",
        "  tokenized_message = tokenizer(message)\n",
        "\n",
        "  for token in tokenized_message:\n",
        "    if token in spam_detectors:\n",
        "      # if the token is a potential spam, we get the index of that word and update the count in our vector\n",
        "      index = index_detector[token]\n",
        "      vector[index] += 1\n",
        "    else:\n",
        "      # if the token isn't a potential spam word we just move on\n",
        "      continue\n",
        "      \n",
        "  return vector\n",
        "  \n",
        "get_vector(\"3d b <br> .com bad font font com randoms\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-G3q_qyq6Erp",
        "outputId": "dd7fa371-1815-4008-95ef-d20d2016b1cc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 2., 0., 0., 2., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above output tells me that the message isn't spam as the spam detector words almost never appear.\n",
        "\n",
        "Testing on some of the emails in the dataframe-"
      ],
      "metadata": {
        "id": "B6kzmdD28OzG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_vector(train_df['MESSAGE'].iloc[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yIQaL-q8NIs",
        "outputId": "454a55e5-de95-47ed-f74f-66bba8340c5c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([33.,  4.,  0.,  2.,  9.,  1.,  0.,  6.,  2.,  0.,  0.,  1.,  3.,\n",
              "        0.,  0.,  1.])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This looks like spam as a lot of the spam detector words appear so many times. Can check if this is correct by calling the first message and seeing if it is indeed spam."
      ],
      "metadata": {
        "id": "P2tBkiv38kh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.iloc[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9UDdMrM8YjG",
        "outputId": "e4edef22-e250-4a9d-b3bb-2f3d6a1a6bff"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CATEGORY                                                     1\n",
              "MESSAGE      \\n\\n<HTML><FONT  BACK=\"#ffffff\" style=\"BACKGRO...\n",
              "FILE_NAME               00118.141d803810acd9d4fc23db103dddfcd9\n",
              "Name: 0, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The category is 1, meaning it is indeed spam."
      ],
      "metadata": {
        "id": "6iLixKQT87_X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_vector(train_df['MESSAGE'].iloc[10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcW88f2F87Hk",
        "outputId": "6d42e580-4d61-457f-a7af-f505089e7957"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Not spam as only of the spam detector words appears and that too just once."
      ],
      "metadata": {
        "id": "rqgb7KFA9LRk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.iloc[10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ov_KSDts9Re7",
        "outputId": "4221bf31-be13-4efc-d69c-6e87dd1c7e76"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CATEGORY                                                     0\n",
              "MESSAGE      \\n\\n>\\n\\n>hi i was just wondering if anyone ex...\n",
              "FILE_NAME               02464.95f59bae730edc01ce4f88d98791ffca\n",
              "Name: 10, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confirmed not spam"
      ],
      "metadata": {
        "id": "9ckKuocR9S_R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now the machine learning part begins"
      ],
      "metadata": {
        "id": "YSUn_Nky9xA9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We want to get a vector like above for each message in the dataframe and match up each vector with whether it is spam or not spam.\n",
        "\n",
        "X represents a matrix of inputs. Each row is a vector\n",
        "\n",
        "y represents whether that vector corresponds to spam or not spam\n",
        "\n",
        "In other words, we now get the X and y values for training and testing from the dataframe."
      ],
      "metadata": {
        "id": "7xc3IfOa-O-r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def df_to_X_y(df):\n",
        "\n",
        "  # list that will keep vectors of each message\n",
        "  vectors = []\n",
        "  # y is spam/not spam, i.e., 1 or 0\n",
        "  y = df['CATEGORY'].to_numpy().astype(int)\n",
        "  messages = df[\"MESSAGE\"]\n",
        "\n",
        "  for message in messages:\n",
        "    vector = get_vector(message)\n",
        "    vectors.append(vector)\n",
        "  \n",
        "  # X is the numpy array of vectors\n",
        "  X = np.array(vectors).astype(int)\n",
        "  return X, y"
      ],
      "metadata": {
        "id": "1407TVMN9u8F"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can split the X and y to training and testing data"
      ],
      "metadata": {
        "id": "gXPMBdkKAgpr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = df_to_X_y(train_df)\n",
        "X_test, y_test = df_to_X_y(test_df)\n",
        "\n",
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZpHcf-oAlYK",
        "outputId": "ea9775af-ad47-436f-e792-d25b2d779bff"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4636, 16), (4636,), (1160, 16), (1160,))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shapes check out. Training X and y have 4636 rows as that is the number of emails in the training dataset. Columns are the number of elements in spam detectors. A similar explanation for testing."
      ],
      "metadata": {
        "id": "PDF0gUqCBHWB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling so the model can learn better\n",
        "\n",
        "scaler = MinMaxScaler().fit(X_train)\n",
        "X_train, X_test = scaler.transform(X_train), scaler.transform(X_test)\n",
        "\n",
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syPbHtlbDQRa",
        "outputId": "d3debbc4-a194-4009-cc43-1a46054eff2a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.04064039, 0.00245851, 0.        , ..., 0.        , 0.        ,\n",
              "        0.00176367],\n",
              "       [0.0270936 , 0.00860479, 0.04065041, ..., 0.00363636, 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.00406504, ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       ...,\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.00406504, ..., 0.        , 0.        ,\n",
              "        0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest Classifier"
      ],
      "metadata": {
        "id": "aERtrSLUDtpw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random_forest = RandomForestClassifier().fit(X_train, y_train)\n",
        "\n",
        "print(classification_report(y_test, random_forest.predict(X_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTea_FPGBnoo",
        "outputId": "85fc5e51-3399-4d0c-ab52-b941bbd1c75d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.96      0.90       788\n",
            "           1       0.89      0.64      0.75       372\n",
            "\n",
            "    accuracy                           0.86      1160\n",
            "   macro avg       0.87      0.80      0.82      1160\n",
            "weighted avg       0.86      0.86      0.85      1160\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "linear_regression = LogisticRegression().fit(X_train, y_train)\n",
        "\n",
        "print(classification_report(y_test, linear_regression.predict(X_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "komf_DynD2km",
        "outputId": "acee7109-deb9-4c10-e1ce-2cf0fb0790f7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      1.00      0.86       788\n",
            "           1       0.99      0.34      0.51       372\n",
            "\n",
            "    accuracy                           0.79      1160\n",
            "   macro avg       0.88      0.67      0.69      1160\n",
            "weighted avg       0.84      0.79      0.75      1160\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Random Forest Classifier gives better scores then Linear Regression. Therefore it may be a better indicator."
      ],
      "metadata": {
        "id": "rjEI3venD9lV"
      }
    }
  ]
}